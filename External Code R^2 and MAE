# R¬≤ UND MAE EVALUATION SCRIPT
# F√ºr Football Player Market Value Analysis Project
# Erstellt f√ºr detaillierte Performance-Evaluation und Ergebnis-Speicherung

import pandas as pd
import numpy as np
import glob
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
import warnings
from datetime import datetime
import os

# F√ºr detaillierte Kommentare (Benutzer ist Anf√§nger in Python)
# XGBoost f√ºr bessere Performance hinzuf√ºgen
try:
    from xgboost import XGBRegressor
    XGBOOST_AVAILABLE = True
    print("‚úÖ XGBoost verf√ºgbar f√ºr erweiterte ML-Analyse!")
except ImportError:
    XGBOOST_AVAILABLE = False
    print("‚ö†Ô∏è XGBoost nicht verf√ºgbar - verwende nur Random Forest")

# Warnungen unterdr√ºcken f√ºr saubere Ausgabe
warnings.filterwarnings('ignore')

print("üéØ R¬≤ UND MAE EVALUATION SCRIPT")
print("=" * 60)
print("üìä Analysiert Machine Learning Performance f√ºr Marktwert-Prediction")
print("üíæ Speichert Ergebnisse automatisch im Marktanalyse-Ordner")
print("=" * 60)

# Lade Dataset (gleicher Pfad wie Hauptscript)
csv_folder = r"C:\Users\vinay\Desktop\Uni\Semester 6\Data Science in Practice\Project\csv files"
print(f"\nüìÇ Lade Dataset aus: {csv_folder}")

try:
    # Lade alle CSV-Dateien
    all_files = glob.glob(csv_folder + "/*.csv")
    print(f"   üìÅ Gefundene CSV-Dateien: {len(all_files)}")
    
    # Kombiniere alle Dateien
    data = pd.concat([pd.read_csv(f) for f in all_files], ignore_index=True)
    print(f"   üìä Gesamt-Datens√§tze geladen: {len(data):,}")
    
except Exception as e:
    print(f"‚ùå FEHLER beim Laden der Daten: {e}")
    print("üí° Stelle sicher, dass der CSV-Ordner existiert und Dateien enth√§lt")
    exit()

# Datenbereinigung (Essential Features)
print(f"\nüîß DATENBEREINIGUNG...")
original_size = len(data)
print(f"   üìä Urspr√ºngliche Gr√∂√üe: {original_size:,} Eintr√§ge")

# Nur die wichtigsten Spalten f√ºr ML beibehalten
essential_columns = ["goals", "assists", "minutes_played", "yellow_cards", "red_cards"]
data = data.dropna(subset=essential_columns)

cleaned_size = len(data)
retention_rate = (cleaned_size / original_size) * 100
print(f"   ‚úÖ Nach Bereinigung: {cleaned_size:,} Eintr√§ge ({retention_rate:.1f}% behalten)")

# Feature Engineering (vereinfacht aber effektiv)
print(f"\n‚öôÔ∏è FEATURE ENGINEERING...")

# 1. Basis-Effizienz-Metriken (wichtig f√ºr Marktwert)
data["goal_efficiency"] = data["goals"] / data["minutes_played"].replace(0, 1)
data["assist_efficiency"] = data["assists"] / data["minutes_played"].replace(0, 1)
print("   ‚úÖ Effizienz-Metriken erstellt (Tore & Assists pro Minute)")

# 2. Kombinierte Performance-Metriken (Standard in Sports Analytics)
data["goal_contributions_per_90"] = ((data["goals"] + data["assists"]) / data["minutes_played"] * 90).replace([np.inf, -np.inf], 0)
data["total_contributions"] = data["goals"] + data["assists"]
print("   ‚úÖ Performance-Metriken erstellt (G+A pro 90min)")

# 3. Disziplin-Score (wichtig f√ºr Marktwert)
data["discipline_score"] = 1 / (1 + data["yellow_cards"] + data["red_cards"] * 3)
data["cards_per_90"] = ((data["yellow_cards"] + data["red_cards"]) / data["minutes_played"] * 90).replace([np.inf, -np.inf], 0)
print("   ‚úÖ Disziplin-Metriken erstellt")

# 4. Erweiterte ML-Features f√ºr bessere R¬≤ Performance
data["minutes_per_goal"] = data["minutes_played"] / (data["goals"] + 1)  # +1 verhindert Division durch 0
data["minutes_per_contribution"] = data["minutes_played"] / (data["total_contributions"] + 1)
data["efficiency_premium"] = (data["goal_efficiency"] + data["assist_efficiency"]) * 1000
print("   ‚úÖ Erweiterte ML-Features erstellt")

# 5. Position-basierte Features (sehr wichtig f√ºr Marktwert!)
# Erstelle Smart Position Assignment basierend auf Performance
def assign_smart_position(row):
    """
    Intelligente Position-Zuweisung basierend auf Performance-Charakteristika
    Erkl√§rt f√ºr Python-Anf√§nger: Diese Funktion schaut sich die Spieler-Performance an
    und versucht herauszufinden, welche Position der Spieler spielt
    """
    goals_per_90 = row.get("goal_contributions_per_90", 0)
    
    if goals_per_90 > 0.8:  # Viele Tore+Assists = Offensiv
        return "St√ºrmer"
    elif goals_per_90 > 0.4:  # Mittlere Performance = Mittelfeld
        return "Mittelfeld"
    else:  # Wenige Tore = Defensiv
        return "Verteidiger"

data["position_category"] = data.apply(assign_smart_position, axis=1)

# Position-Multiplikatoren (basierend auf echten Transfermarkt-Daten)
position_multipliers = {
    "St√ºrmer": 1.2,      # St√ºrmer sind am teuersten
    "Mittelfeld": 1.0,   # Standard-Bewertung
    "Verteidiger": 0.9   # Verteidiger g√ºnstiger
}
data["position_multiplier"] = data["position_category"].map(position_multipliers)
print("   ‚úÖ Positions-Features erstellt")

# TARGET VARIABLE: Dynamische Marktwerte erstellen
print(f"\nüéØ TARGET VARIABLE ERSTELLUNG...")
print("   üí° Da keine echten Marktwerte verf√ºgbar sind, erstellen wir")
print("   üí° performance-basierte dynamische Marktwerte f√ºr ML-Training")

# Basis-Marktwert-Formel (rational und realistisch)
data["base_market_value"] = (
    500_000 +                           # Basis f√ºr Profi-Spieler
    data["goals"] * 200_000 +           # 200k pro Tor (realistisch)
    data["assists"] * 100_000 +         # 100k pro Assist
    data["minutes_played"] * 50 +       # 50‚Ç¨ pro Minute (Erfahrung)
    - data["yellow_cards"] * 10_000 -   # Disziplin-Malus
    - data["red_cards"] * 50_000        # Schwerer Disziplin-Malus
)

# Performance-Multiplikatoren f√ºr Realismus
data["performance_factor"] = (
    data["discipline_score"] *          # Disziplin wichtig
    data["position_multiplier"] *       # Position-Premium
    (1 + data["goal_contributions_per_90"] * 0.5)  # Performance-Bonus
)

# Finale dynamische Marktwerte (mit Variation f√ºr ML-Training)
np.random.seed(42)  # F√ºr reproduzierbare Ergebnisse
variation = np.random.uniform(0.8, 1.2, len(data))  # 80-120% Variation
data["target_market_value"] = (data["base_market_value"] * data["performance_factor"] * variation).round(0).astype(int)

print(f"   ‚úÖ Dynamische Marktwerte erstellt:")
print(f"      ‚Ä¢ Min: {data['target_market_value'].min():,} ‚Ç¨")
print(f"      ‚Ä¢ Max: {data['target_market_value'].max():,} ‚Ç¨")
print(f"      ‚Ä¢ Median: {data['target_market_value'].median():,} ‚Ç¨")

# ML-Features f√ºr Training definieren
ml_features = [
    # Basis-Performance
    "goals", "assists", "minutes_played", "yellow_cards", "red_cards",
    
    # Effizienz-Metriken
    "goal_efficiency", "assist_efficiency", "goal_contributions_per_90",
    
    # Disziplin & Konsistenz
    "discipline_score", "cards_per_90",
    
    # Erweiterte Features
    "total_contributions", "minutes_per_goal", "minutes_per_contribution",
    "efficiency_premium", "position_multiplier"
]

print(f"\nü§ñ ML-FEATURES F√úR TRAINING:")
for i, feature in enumerate(ml_features, 1):
    print(f"   {i:2d}. {feature}")

# Pr√ºfe Feature-Verf√ºgbarkeit
available_features = [f for f in ml_features if f in data.columns]
missing_features = [f for f in ml_features if f not in data.columns]

if missing_features:
    print(f"‚ö†Ô∏è Fehlende Features: {missing_features}")
    ml_features = available_features

print(f"‚úÖ Verf√ºgbare ML-Features: {len(ml_features)}")

# Bereite ML-Daten vor
X = data[ml_features].fillna(0)  # F√ºlle fehlende Werte mit 0
y = data["target_market_value"]

print(f"\nüìä ML-DATASET VORBEREITUNG:")
print(f"   ‚Ä¢ Features (X): {X.shape}")
print(f"   ‚Ä¢ Target (y): {y.shape}")
print(f"   ‚Ä¢ Fehlende Werte in X: {X.isnull().sum().sum()}")
print(f"   ‚Ä¢ Fehlende Werte in y: {y.isnull().sum()}")

# Train-Test Split (70% Training, 30% Testing)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

print(f"\n‚úÇÔ∏è TRAIN-TEST SPLIT:")
print(f"   ‚Ä¢ Training-Daten: {X_train.shape[0]:,} Eintr√§ge")
print(f"   ‚Ä¢ Test-Daten: {X_test.shape[0]:,} Eintr√§ge")

# MODELL-TRAINING UND EVALUATION
print(f"\nü§ñ MODELL-TRAINING UND EVALUATION")
print("=" * 50)

# Dictionary f√ºr Ergebnisse
results = {}

# 1. RANDOM FOREST (Baseline-Modell)
print("üå≤ Training Random Forest...")
rf_model = RandomForestRegressor(
    n_estimators=100,    # 100 B√§ume (gute Balance zwischen Performance und Speed)
    random_state=42,     # F√ºr reproduzierbare Ergebnisse
    n_jobs=-1           # Nutze alle CPU-Kerne
)

# Training
rf_model.fit(X_train, y_train)

# Predictions
rf_pred = rf_model.predict(X_test)

# Metriken berechnen
rf_mae = mean_absolute_error(y_test, rf_pred)
rf_r2 = r2_score(y_test, rf_pred)
rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))

results['Random Forest'] = {
    'model': rf_model,
    'predictions': rf_pred,
    'mae': rf_mae,
    'r2': rf_r2,
    'rmse': rf_rmse
}

print(f"   ‚úÖ Random Forest trainiert!")
print(f"      ‚Ä¢ MAE: {rf_mae:,.0f} ‚Ç¨")
print(f"      ‚Ä¢ R¬≤: {rf_r2:.3f} ({rf_r2*100:.1f}%)")
print(f"      ‚Ä¢ RMSE: {rf_rmse:,.0f} ‚Ç¨")

# 2. XGBOOST (Falls verf√ºgbar - meist bessere Performance)
if XGBOOST_AVAILABLE:
    print("\n‚ö° Training XGBoost...")
    
    xgb_model = XGBRegressor(
        n_estimators=200,        # Mehr B√§ume f√ºr bessere Performance
        max_depth=6,             # Tiefe der B√§ume
        learning_rate=0.1,       # Lernrate
        random_state=42,         # Reproduzierbarkeit
        n_jobs=-1,              # Alle CPU-Kerne nutzen
        verbosity=0             # Keine Debug-Ausgaben
    )
    
    # Training
    xgb_model.fit(X_train, y_train)
    
    # Predictions
    xgb_pred = xgb_model.predict(X_test)
    
    # Metriken berechnen
    xgb_mae = mean_absolute_error(y_test, xgb_pred)
    xgb_r2 = r2_score(y_test, xgb_pred)
    xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_pred))
    
    results['XGBoost'] = {
        'model': xgb_model,
        'predictions': xgb_pred,
        'mae': xgb_mae,
        'r2': xgb_r2,
        'rmse': xgb_rmse
    }
    
    print(f"   ‚úÖ XGBoost trainiert!")
    print(f"      ‚Ä¢ MAE: {xgb_mae:,.0f} ‚Ç¨")
    print(f"      ‚Ä¢ R¬≤: {xgb_r2:.3f} ({xgb_r2*100:.1f}%)")
    print(f"      ‚Ä¢ RMSE: {xgb_rmse:,.0f} ‚Ç¨")

# ERGEBNISSE VERGLEICHEN UND BESTES MODELL W√ÑHLEN
print(f"\nüèÜ MODELL-VERGLEICH:")
print("=" * 50)

best_model_name = None
best_r2 = -999

for model_name, result in results.items():
    mae = result['mae']
    r2 = result['r2']
    rmse = result['rmse']
    
    # Performance-Kategorie bestimmen
    if r2 >= 0.7:
        category = "ü•á EXZELLENT"
    elif r2 >= 0.5:
        category = "ü•à SEHR GUT"
    elif r2 >= 0.3:
        category = "ü•â GUT"
    else:
        category = "üìä BASIS"
    
    print(f"\n{category} {model_name}:")
    print(f"   ‚Ä¢ R¬≤ Score: {r2:.3f} ({r2*100:.1f}%)")
    print(f"   ‚Ä¢ MAE: {mae:,.0f} ‚Ç¨")
    print(f"   ‚Ä¢ RMSE: {rmse:,.0f} ‚Ç¨")
    
    # Bestes Modell tracker
    if r2 > best_r2:
        best_r2 = r2
        best_model_name = model_name

print(f"\nüéØ GEWINNER: {best_model_name} mit R¬≤ = {best_r2:.3f}")

# Feature Importance (nur f√ºr das beste Modell)
best_model = results[best_model_name]['model']

if hasattr(best_model, 'feature_importances_'):
    feature_importance = pd.DataFrame({
        'Feature': ml_features,
        'Importance': best_model.feature_importances_
    }).sort_values('Importance', ascending=False)
    
    print(f"\nüéØ FEATURE IMPORTANCE ({best_model_name}):")
    for i, (_, row) in enumerate(feature_importance.head(5).iterrows(), 1):
        print(f"   {i}. {row['Feature']}: {row['Importance']:.3f} ({row['Importance']*100:.1f}%)")

# DETAILLIERTE ERGEBNISSE SPEICHERN
print(f"\nüíæ SPEICHERE ERGEBNISSE...")

# Erstelle Ausgabe-Ordner falls nicht vorhanden
output_dir = r"C:\Users\vinay\Desktop\Uni\Semester 6\Data Science in Practice\Marktanalyse"
os.makedirs(output_dir, exist_ok=True)

# Timestamp f√ºr eindeutige Dateinamen
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

# 1. DETAILLIERTER ERGEBNISBERICHT (TXT)
report_file = os.path.join(output_dir, f"R2_MAE_Report_{timestamp}.txt")

with open(report_file, 'w', encoding='utf-8') as f:
    f.write("R¬≤ UND MAE EVALUATION REPORT\n")
    f.write("=" * 60 + "\n")
    f.write(f"Erstellt am: {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}\n")
    f.write(f"Dataset: {len(data):,} Eintr√§ge nach Bereinigung\n")
    f.write(f"Features: {len(ml_features)} ML-Features\n")
    f.write(f"Train/Test: {len(X_train):,} / {len(X_test):,}\n\n")
    
    f.write("MODELL-PERFORMANCE:\n")
    f.write("-" * 30 + "\n")
    
    for model_name, result in results.items():
        mae = result['mae']
        r2 = result['r2']
        rmse = result['rmse']
        
        f.write(f"\n{model_name}:\n")
        f.write(f"  R¬≤ Score: {r2:.4f} ({r2*100:.2f}%)\n")
        f.write(f"  MAE: {mae:,.0f} ‚Ç¨\n")
        f.write(f"  RMSE: {rmse:,.0f} ‚Ç¨\n")
    
    f.write(f"\nGEWINNER: {best_model_name}\n")
    f.write(f"Beste R¬≤: {best_r2:.4f}\n\n")
    
    # Feature Importance hinzuf√ºgen
    if 'feature_importance' in locals():
        f.write("TOP-FEATURES F√úR MARKTWERT:\n")
        f.write("-" * 30 + "\n")
        for i, (_, row) in enumerate(feature_importance.head(10).iterrows(), 1):
            f.write(f"{i:2d}. {row['Feature']}: {row['Importance']:.4f}\n")
    
    f.write(f"\nML-FEATURES VERWENDET:\n")
    f.write("-" * 30 + "\n")
    for i, feature in enumerate(ml_features, 1):
        f.write(f"{i:2d}. {feature}\n")

print(f"   ‚úÖ Report gespeichert: {report_file}")

# 2. ERGEBNISSE ALS CSV (f√ºr Excel-Import)
results_df = pd.DataFrame({
    'Modell': list(results.keys()),
    'R2_Score': [results[k]['r2'] for k in results.keys()],
    'R2_Prozent': [results[k]['r2']*100 for k in results.keys()],
    'MAE_Euro': [results[k]['mae'] for k in results.keys()],
    'RMSE_Euro': [results[k]['rmse'] for k in results.keys()]
})

csv_file = os.path.join(output_dir, f"R2_MAE_Results_{timestamp}.csv")
results_df.to_csv(csv_file, index=False, encoding='utf-8')
print(f"   ‚úÖ CSV gespeichert: {csv_file}")

# 3. FEATURE IMPORTANCE ALS CSV
if 'feature_importance' in locals():
    feature_file = os.path.join(output_dir, f"Feature_Importance_{timestamp}.csv")
    feature_importance.to_csv(feature_file, index=False, encoding='utf-8')
    print(f"   ‚úÖ Feature Importance gespeichert: {feature_file}")

# 4. VISUALISIERUNGEN ERSTELLEN UND SPEICHERN
print(f"\nüìä ERSTELLE VISUALISIERUNGEN...")

# Plot 1: Predicted vs Actual
plt.figure(figsize=(15, 10))

# Subplot 1: Predicted vs Actual (Bestes Modell)
plt.subplot(2, 2, 1)
best_predictions = results[best_model_name]['predictions']
plt.scatter(y_test/1000000, best_predictions/1000000, alpha=0.6, color='darkblue', s=40)
plt.plot([y_test.min()/1000000, y_test.max()/1000000], 
         [y_test.min()/1000000, y_test.max()/1000000], 'r--', lw=2)
plt.xlabel('Echter Marktwert (Mio ‚Ç¨)', fontsize=12)
plt.ylabel('Vorhergesagter Marktwert (Mio ‚Ç¨)', fontsize=12)
plt.title(f'Predicted vs Actual ({best_model_name})\nR¬≤ = {best_r2:.3f}', fontsize=14, fontweight='bold')
plt.grid(True, alpha=0.3)

# Subplot 2: Model Comparison
plt.subplot(2, 2, 2)
model_names = list(results.keys())
r2_scores = [results[k]['r2'] for k in model_names]
colors = ['steelblue', 'orange'] if len(model_names) == 2 else ['steelblue']

bars = plt.bar(model_names, r2_scores, color=colors)
plt.title('Model Comparison (R¬≤ Score)', fontsize=14, fontweight='bold')
plt.ylabel('R¬≤ Score', fontsize=12)
plt.ylim(0, max(r2_scores) * 1.1)

# Werte auf Balken anzeigen
for bar, score in zip(bars, r2_scores):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
             f'{score:.3f}', ha='center', fontweight='bold')

plt.grid(True, alpha=0.3, axis='y')

# Subplot 3: Feature Importance (Top 8)
if 'feature_importance' in locals():
    plt.subplot(2, 2, 3)
    top_features = feature_importance.head(8)
    plt.barh(range(len(top_features)), top_features['Importance'], color='green', alpha=0.7)
    plt.yticks(range(len(top_features)), top_features['Feature'])
    plt.xlabel('Importance', fontsize=12)
    plt.title('Top Features f√ºr Marktwert', fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3, axis='x')

# Subplot 4: Residuals (Fehler-Analyse)
plt.subplot(2, 2, 4)
residuals = y_test - best_predictions
plt.scatter(best_predictions/1000000, residuals/1000000, alpha=0.6, color='green', s=40)
plt.axhline(y=0, color='r', linestyle='--', linewidth=2)
plt.xlabel('Vorhergesagter Marktwert (Mio ‚Ç¨)', fontsize=12)
plt.ylabel('Vorhersage-Fehler (Mio ‚Ç¨)', fontsize=12)
plt.title('Fehler-Analyse (Residuals)', fontsize=14, fontweight='bold')
plt.grid(True, alpha=0.3)

plt.tight_layout()

# Speichere Plot
plot_file = os.path.join(output_dir, f"R2_MAE_Analysis_{timestamp}.png")
plt.savefig(plot_file, dpi=300, bbox_inches='tight')
print(f"   ‚úÖ Visualisierung gespeichert: {plot_file}")
plt.show(block=False)

# FINALE ZUSAMMENFASSUNG
print(f"\nüéØ FINALE ZUSAMMENFASSUNG")
print("=" * 60)
print(f"‚úÖ EVALUATION ABGESCHLOSSEN!")
print(f"   üìä Beste Performance: {best_model_name}")
print(f"   üéØ R¬≤ Score: {best_r2:.3f} ({best_r2*100:.1f}%)")
print(f"   üí∞ MAE: {results[best_model_name]['mae']:,.0f} ‚Ç¨")
print(f"   üìà Qualit√§t: ", end="")

if best_r2 >= 0.7:
    print("EXZELLENT (Publikationsreif!)")
elif best_r2 >= 0.5:
    print("SEHR GUT (Hervorragend f√ºr Uni-Projekt!)")
elif best_r2 >= 0.3:
    print("GUT (Solide Performance!)")
else:
    print("BASIS (Verbesserung m√∂glich)")

print(f"\nüíæ ALLE ERGEBNISSE GESPEICHERT IN:")
print(f"   üìÅ {output_dir}")
print(f"   üìÑ {os.path.basename(report_file)}")
print(f"   üìä {os.path.basename(csv_file)}")
print(f"   üìà {os.path.basename(plot_file)}")

if 'feature_importance' in locals():
    print(f"   üéØ {os.path.basename(feature_file)}")

print(f"\nüéì BEREIT F√úR PR√ÑSENTATION!")
print("=" * 60) 
